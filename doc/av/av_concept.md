# 音视频概述

[TOC]

## 流媒体收发过程

![流媒体收发过程](.\res\流媒体收发过程.jpg)

如上，流媒体传输主要有三个阶段：采集，编码，传输。

* 采集：需要对音视频信号进行采集，采集方式根据实际需求而定，如音视频采集卡，摄像头，麦克风。
* 编码：编码将音视频信号转换为数字信号，以便对其进行传输，主要有H264，其中分为encode，mux。
* 传输：传输是将音视频信号传输到后端，主要有RTMP，RTSP，WebRtc等。

![音视频采集](.\res\mux.webp)

流媒体接收主要有三个阶段：接收，解码，播放。

* 接收：接收将后端的音视频信号进行接收，主要有RTMP，RTSP，WebRtc等。

* 解码：将音视频信号进行解码，解码主要是将数字信号转为音视频信号，主要有H264等。

* 播放：是将音视频信号数据进行同步后播放，主要有VLC，也有自研的[kplayer](https://github.com/reachithard/kplayer)

  ![音视频播放](.\res\demux.webp)

## 视频主要概念

![视频主要概念](.\res\video_base.png)

* 码率

  码率，又叫比特率，单位时间内传输的数据量，单位一般为kbps(千位每秒)。需要注意的是，这里b代表bit，而不是byte。计算公式：平均码率(kbps)=文件大小(kb)X8/时间(s)。动态码率(kbps)=每秒传输数据量(kb)X8。

  恒定码率：CBR，码率稳定可控，带宽要求不高，图像变化量比较大时方块效应比较明显。

  动态码率：VBR，码率波动较大，带宽要求较高，图像变化量比较大时方块效应有所改善。发生网络抖动时，比较容易丢包，需要重传，或者FEC前向纠错，从而带来延时。

* 分辨率
  分辨率又称为解析度，分辨率越高，像素越多，图像越清晰。

* 帧率

  测量显示帧数的量度，单位为每秒显示帧数(FPS，全称为Frame Per Second)。

* stride

  指在内存中每行像素所占的空间。为了实现内存对齐每行像素在内存中所占的空间并不一定是图像的宽度。 

  ![stride](.\res\stride.webp)

* 帧

  帧是视频开发常见的一个基本概念，可以表示为一张画面，一个段视频本质上就是有许多画面组成，因此，一个视频就是由许许多多的视频帧组成。

  在视频数据的压缩处理中，每帧都代表着一副画面，由于视频前后两帧的画面极为相似，因此可以通过前一帧的画面数据来进行压缩或者解压缩，根据参考的帧的不同，可以划分为 I 帧、P 帧 和 B 帧。

  - I 帧：（Intra Picture）帧内编码帧，也叫关键帧，I 帧不需要参考其他帧就可以进行解码。帧内压缩技术。
  - P 帧：（Predictive-Frame）向前预测编码帧，即需要参考前面的一帧才能进行解码，帧间压缩技术。
  - B 帧：（bi-directional interpolated prediction frame）双向预测内插编码帧，也叫双向预测帧。即需要参考前面已编码的帧，又需要参考图像序列后面的已编码帧，才能进行解码，帧间压缩技术。
  - IDR帧：IDR帧也是I帧，但I帧不一定是IDR帧，出现了IDR帧立即刷新。

* GOP

  GOP ，Group of Picture ，指的是两个 I 帧之间的间隔。

* PTS 和 DTS

  由于存在 B 帧和 P 帧，因此某一帧的解码顺序和显示顺序有可能是不一样的，因此就有课 PTS 和 DTS 的概念。

  * DTS, Decoding TimeStamp 解码时间戳，用于告诉解码器什么时候解码。
  * PTS, Presentation TimeStamp 显示时间戳，用于告诉播放器在什么时候显示这一帧。

![pts和dts](.\res\PTS_DTS.webp)

## 视频编码

数字化后的视频信号能进行压缩主要依据两个基本条件：

l  数据冗余。例如如空间冗余、时间冗余、信息熵冗余等，即图像的各像素之间存在着很强的相关性。消除这些冗余并不会导致信息损失，属于无损压缩。

- **空间冗余** 比如说将一帧图像划分成一个个 `16x16` 的块之后，相邻的块很多时候都有比较明显的相似性，这种就叫空间冗余。
- **时间冗余** 一个帧率为 `25fps` 的视频中前后两帧图像相差只有 `40ms`，两张图像的变化是比较小的，相似性很高，这种叫做时间冗余。
- **信息熵冗余** 我们一般会使用 `Zip` 等压缩工具去压缩文件，将文件大小减小，这个对于图像来说也是可以做的，这种冗余叫做信息熵冗余。

l  视觉冗余。人眼的一些特性比如亮度辨别阈值，视觉阈值，对亮度和色度的敏感度不同，使得在编码的时候引入适量的误差，也不会被察觉出来。可以利用人眼的视觉特性，以一定的客观失真换取数据压缩。这种压缩属于有损压缩。

### 视频压缩技术

* 帧内预测压缩，解决的是空域数据冗余问题。

* 帧间预测压缩（运动估计与补偿），解决的是时域数据冗徐问题。

* 整数离散余弦变换（DCT），将空间上的相关性变为频域上无关的数据然后进行量化。

* CABAC压缩。

## 音频主要概念

- 采样频率：1秒内采集到的采样点的个数，一般用赫兹Hz来表示。根据奈奎斯特采样定理在进行模拟/数字信号的转换过程中，当采样频率fs大于信号中最高频率fmax的2倍时，采样之后的数字信号才可以完整地保留原始信号中的信息。也就是说采样率和保留的声音频率基本上是2倍的关系。
- 位深：振动幅度的表达精确程度或者说粒度。
- 通道数：同一时间采集或播放的音频信号的总数。
- 比特率：每秒传输的bit数，间接衡量声音质量的一个标准。没有压缩的音频数据的比特率 = 采样频率 * 采样精度 * 通道数。
- 码率：压缩后的音频数据的比特率。
  - 码率越大，压缩效率越低，音质越好，压缩后数据越大。
  - 码率 = 音频文件大小 / 时长。
- 帧：每次编码的采样单元数，比如MP3通常是 **1152** 个采样点作为一个编码单元，AAC通常是 **1024** 个采样点作为一个编码单元。
- 帧长：可以指每帧播放持续的时间。每帧持续时间(秒)= 每帧采样点数 / 采样频率(HZ)。比如：MP3 48k，1152个采样点，每帧则为24毫秒，1152/48000 = 0.024秒 = 24毫秒；也可以指压缩后每帧的数据长度。
- 交错模式：数字音频信号存储的方式。数据以连续帧的方式存放，即首先记录帧1的左声道样本和右声道样本，再开始帧2的记录...
- 非交错模式：首先记录的是一个周期内所有帧的左声道样本，再记录所有右声道样本。
- 窄带(8kHz采样率)及宽带(16kHz采样率)下，带调频所占用的频带宽度较窄，信号质量较高，但传输数据量有限；而宽带调频所占用的频带宽度比较宽，传输数据量大，但信号质量可能会受到噪声的影响。

### 音频编码技术

数字音频压缩编码在保证信号在听觉方面不产生失真的前提下，对音频数据信号进行尽可能大的压缩，降低数据量。数字音频压缩编码采取去除声音信号中冗余成分的方法来实现。所谓冗余成分指的是音频中不能被人耳感知到的信号，它们对确定声音的音色，音调等信息没有任何的帮助。

### 音频处理

TODO webrtc处理

## 音视频同步

| 名称                  | 实现                     |
| --------------------- | ------------------------ |
| Audio Master          | 同步视频到音频           |
| Video Master          | 同步音频到视频           |
| External Clock Master | 同步音频和视频到外部时钟 |

一般情况下选择：Audio Master > External Clock Master > Video Master

## 音视频变速

一般情况下，如果存在音频，并且以音频为主时钟，则可进行soundtouch或者sonic进行音视频变速，如果不存在，则需要修改pts。可参考[kplayer](https://github.com/reachithard/kplayer)

## 丢包补偿

* 发送端补偿包括前向差错纠正、交织和重传技术
* 接受端补偿包括了多种错误隐蔽算法